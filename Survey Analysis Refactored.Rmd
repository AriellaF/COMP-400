---
title: "Survey Analysis Refactored"
author: "Ariella Fuzaylov"
date: "3/13/2021"
output: pdf_document
---

```{r setup, include=FALSE}
library(ggplot2)
library(tidyverse)
library(tm)
library(SnowballC)
library(textclean)
library(wordcloud)
library(FactoMineR)
library(factoextra)
library("gplots")
library(corrplot)
library(dummy)

```

## Loading Data and Update Header

```{r load data}
my.data=read.csv("Online Recipe Sharing.csv", header=TRUE)
colnames(my.data)
colnames(my.data)<-c("Timestamp", "Age", "Primary.Meal.Prepper", "Household.Dietary.Restriction",
"Home.Cooking.Frequency", 
"Primary.Recipe.Format", 
"Primary.Search.Website",
"Enjoyed.Website.Searching", "Comments.Enjoyed.Website.Searching", "NOT.Enjoyed.Website.Searching", "Comments.NOT.Enjoyed.Website.Searching", "Recipe.Search.Bar.Frequency", 
"Previous.Recipe.Search.Frequency",
"Browsing.While.Searching.Frequecny", 
"Click.Rate", 
"Search.Browse.Same.Websites",
"Primary.Browsing.Website", 
"Enjoyed.Website.Browsing", 
"Comments.Enjoyed.Website.Browsing", "NOT.Enjoyed.Website.Browsing", "Comments.NOT.Enjoyed.Website.Browsing", "Primary.Source.of.Reviews",
"Source.of.Influential.Reviews", "Frequency.Reviews.Effect.Behavior", 
"Frequency.Seek.Out.Review", 
"Frequency.of.Review", 
"Frequency.of.Recipe.Saving", 
"Method.of.Recipe.Saving", 
"Modification.Frequency", 
"Modification.Influence.Factors",
"Modification.Record.Frequency", 
"Modification.Record.Method", "Satisfaction.with.Available.Record.Methods", 
"Interest.in.Improved.Record.Method",
"Frequency.of.Recipe.Discussion", "Frequency.of.Reading.Discussion",
"Primary.Discussion.Medium", "Enjoyed.Features.of.Discussion.Mediums", "Ingredients.L.V.Above", 
"Ingredients.L.Comments.Inline.V.Below", "Ingredients.Above.Comments.Below.V.Inline", "Ingredients.By.Step.V.Above", 
"Ingredients.By.Step.V.Scroll.L", 
"Ingredients.Above.V.Scroll.L")
```
### Re-Factor Data

```{r factoring}
my.data.factored<-my.data
my.data.factored$Age<-as.factor(my.data$Age)

my.data.factored$Primary.Meal.Prepper<-as.factor(my.data.factored$Primary.Meal.Prepper)

my.data.factored$Household.Dietary.Restriction<-as.factor(my.data.factored$Household.Dietary.Restriction)

my.data.factored$Home.Cooking.Frequency<-as.factor(my.data.factored$Home.Cooking.Frequency)

my.data.factored<- mutate(my.data.factored,Primary.Meal.Prepper = fct_collapse(Primary.Meal.Prepper,
                                                              Respondent = c("You", "I cook for myself"),
                                                              other_level = "Other"),
                  Household.Dietary.Restriction=fct_collapse(Household.Dietary.Restriction,
                                                             No="None",
                                                              other_level = "Yes"),
                  Home.Cooking.Frequency=fct_collapse(Home.Cooking.Frequency,Daily=c("Almost every meal","Daily","Every meal"),
                                                      Weekly=c("Several times a week","Once or twice a week"),
                                                      Monthly=c("Once or twice a month")))

```
### Pre-Process Text Data 
```{r process text}
Pre.process <- function(charlist){
  charlist<-charlist[charlist!=""]
  corp<-VCorpus(VectorSource(charlist))
  
  corp <- tm_map(corp, content_transformer(tolower))
  corp <- tm_map(corp, removePunctuation)

  corp<-tm_map(corp, content_transformer(removeWords), stopwords('english'))
  corp<-tm_map(corp,stemDocument)
  corp <- tm_map(corp, stripWhitespace) 
  
  return(corp)
}
Comments.Enjoyed.Searching.corp<-Pre.process(my.data[,9])
Comments.NOT.Enjoyed.Searching.corp<-Pre.process(my.data[,11])
Comments.Enjoyed.Browsing.corp<-Pre.process(my.data[,19])
Comments.NOT.Enjoyed.Browsing.corp<-Pre.process(my.data[,21])
```

### Create Word Cloud
```{r word cloud}
print("Enjoy Searching Responces")
cp <- brewer.pal(8,"Dark2")
wordcloud(words = Comments.Enjoyed.Searching.corp, scale=c(4,0.5), max.words=50,min.freq = 0,random.order=FALSE,
 rot.per=0.25, colors=cp)

print("NOT Enjoy Searching Responces")
wordcloud(words = Comments.NOT.Enjoyed.Searching.corp, scale=c(4,0.5), max.words=50,min.freq = 0,random.order=FALSE,
 rot.per=0.25, colors=cp)

print(" Enjoy Browsing Responces")
wordcloud(words = Comments.Enjoyed.Browsing.corp, scale=c(2.5,0.25), max.words=50,min.freq = 0,random.order=FALSE,
 rot.per=0.25, colors=cp)

print("NOT Enjoy Browsing Responces")
wordcloud(words = Comments.NOT.Enjoyed.Browsing.corp, scale=c(3.5,0.25),min.freq = 0, max.words=50,random.order=FALSE,
 rot.per=0.25, colors=cp)
```

### Create Charts
```{r freq chart}

freqchart <- function(corp){
 ## Drop entries that only occur once. This makes the chart easier to read
  myTdm <- as.matrix(TermDocumentMatrix(corp))
  FreqMat <- data.frame(ST = rownames(myTdm), 
                      Freq = rowSums(myTdm), 
                      row.names = NULL)%>%arrange(desc(Freq))
  FreqMat<-FreqMat[!(FreqMat$Freq == 1),]
  FreqMat
  p<-ggplot(data=FreqMat, aes(x=reorder( ST, -Freq), y=Freq)) +
    geom_bar(stat="identity", fill="dodger blue")+
    theme(axis.text.x = element_text(angle = 90))
  return(p)
}
Comments.Enjoyed.Searching.Plot<-freqchart(Comments.Enjoyed.Searching.corp)
Comments.Enjoyed.Searching.Plot + ggtitle("Enjoy Searching Responces")
Comments.NOT.Enjoyed.Searching.Plot<-freqchart(Comments.NOT.Enjoyed.Searching.corp)
Comments.NOT.Enjoyed.Searching.Plot + ggtitle("NOT Enjoy Searching Responces")
Comments.Enjoyed.Browsing.Plot<-freqchart(Comments.Enjoyed.Browsing.corp)
Comments.Enjoyed.Browsing.Plot + ggtitle("Enjoy Browsing Responces")
Comments.NOT.Enjoyed.Browsing.Plot<-freqchart(Comments.NOT.Enjoyed.Browsing.corp)
Comments.NOT.Enjoyed.Browsing.Plot + ggtitle("NOT Enjoy Browsing Responces")
```

For the sake of this analysis any website that has a test kitchen that creates editorial content or is able to curate content from professional sources is a magazine, a a website with one or two people testing recipes is a blog, and a website that allows users to contribute their own recipes is community based. The information for this classification is found on the website's about page. Additionally, media such as cookbooks and podcasts are classified under Influencers due to their personality driven nature.

```{r searching}
my.data.selected<-my.data.factored[c(7,8,10,17,18,20,22,23,28,37)]
head(my.data.selected)
variables<-c()

 for (i in 1:ncol(my.data.selected)){
  temp<- my.data.selected[i]
  temp<-separate_rows(temp,1, sep = ";")
  variables<-append(variables,temp[[1]])
  variables<-unique(variables)
  data.frame(variables)
 }
variables
cleaned.variables<-c(
  "Mags",
  "Blogs",
  "Google",
  "Youtube",
  "Community Based" ,
  "Mags",
  "Community Based" ,
  "Pinterest",
  "Blogs",
  "TikTok",
  "Mags",
  "Facebook",
  "Reddit",
  "Mags",
  "Mags",
  "Mags",
  "Mags",
  "Instagram",
  "Mags",
  "Friends/Family",
  "Blogs",
  "NA",
  "Blogs",
  "Mags",
  "Instagram",
  "Instagram",
  "None",
  "None",
  "Friends/Family",
  "Online Groups",
  "Other Users",
  "Influencers",
  "Influencers",
  "Facebook",
  "Browser Bookmarks",
  "Digital Filing",
  "Memory",
  "Search History",
  "Save Function",
  "Physical Filing",
  "None",
  "Memory",
  "Memory",
  "Memory",
  "Save Function",
  "Verbal",
  "Verbal",
  "Verbal",
  "Digital Chat",
  "Verbal",
  "Verbal",
  "Digital Chat",
  "Google Docs",
  "Digital Chat",
  "Verbal",
  "Verbal",
  "Verbal",
  "Verbal",
  "Verbal",
  "Verbal",
  "Verbal",
  "Verbal",
  "Digital Chat",
  "None",
  "Digital Chat",
  "Verbal",
  "Digital Chat",
  "Digital Chat",
  "None"
)
names(cleaned.variables)<-variables
```

## The Average User

```{r}
likert.clean<-function(to.clean){
  cut(to.clean,c(0, 1.2, 2.5,3.5,4.5,5.5),right=FALSE,labels=c("Never","Rarely","Sometimes", "Often","Always"))
}

dummies<-function(search.data, to.clean){
  col.names<-c(names(search.data))
  col.names<-col.names[col.names!=to.clean]
  search.data.clean<- search.data%>% separate_rows(to.clean, sep = ";")
  
  search.data.clean[[to.clean]]<-as.character(cleaned.variables[search.data.clean[[to.clean]]])
  
  search.data.dummies<-search.data.clean%>%
    select(to.clean)%>%
    dummy()%>%
    bind_cols(search.data.clean)%>%
    select(-to.clean)%>%
     pivot_longer(cols=-col.names, names_to = "key", values_to = "value")%>%
     filter(value!=0)%>%
    unique()%>%
   spread(key, value, fill = 0)
  
}

search.data<-my.data.clean[c(2,3,4,5,7,8,9,11,12,13)]
search.data<-data.frame(search.data)
colnames(search.data)<-c("Age", "Meal.Prepper","Dietary.Restriction","Home.Cook.Freq","Primary.C",
                         "Enjoyed.C","NOT.Enjoyed.C","Repeat.Search.F","Browse.Search.F","Click.Rate")
search.data<-tibble::rowid_to_column(search.data, "ID")
search.data<- search.data%>% replace_na(list(NOT.Enjoyed
="None"))

to.dummy<-select(cleaned, ends_with(".C"))
to.dummy.cols<-c(colnames(to.dummy))
cleaned<-search.data
for (col in to.dummy.cols){
  cleaned<-dummies(cleaned,c(col))
}
 # cleaned<-dummies(search.data,c("Primary"))
 # cleaned<-dummies(cleaned,c("Enjoyed"))
 # cleaned<-dummies(cleaned, c("NOT.Enjoyed"))


cleaned.likhart<-apply(select(cleaned,ends_with(".F")),2,likert.clean)

cleaned[, colnames(cleaned) %in% colnames(cleaned.likhart)] <- cleaned.likhart
cols<-names(cleaned)
cleaned.factored<-lapply(cleaned[cols], as.factor)
head(cleaned.factored)
```

```{r}
cleaned.search.data<-data.frame(cleaned.factored[-c(1)])
dim(cleaned.search.data)
search.MCA=MCA(cleaned.search.data,graph=FALSE)
fviz_screeplot(search.MCA,addlabels=T)
fviz_mca_var(search.MCA, choice = "mca.cor", repel = TRUE,
             ggtheme = theme_minimal())
fviz_contrib(search.MCA, choice = "var", axes = 1, top = 15)
fviz_mca_var(search.MCA, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, ggtheme = theme_minimal())
```
### Turn MCA/ cleaning into a function so we can group by different things
```{r}
clean.mca<-function(search.data){
  search.data<-tibble::rowid_to_column(search.data, "ID")
  search.data<- search.data%>% replace_na(list(NOT.Enjoyed
  ="None"))
  cleaned<-dummies(search.data,c("Primary"))
  cleaned<-dummies(cleaned,c("Enjoyed"))
  cleaned<-dummies(cleaned, c("NOT.Enjoyed"))
  # cleaned=cleaned%>%mutate(Repeat.Search= cut(Repeat.Search, c(0, 1.2, 2.5,3.5,4.5,5.5),right=FALSE,
  #                                             labels=c("Never","Rarely","Sometimes", "Often","Always")), 
                           # Browse.Search = cut(Browse.Search, c(0, 1.2, 2.5,3.5,4.5,5.5),right=FALSE,
                           #                     labels=c("Never","Rarely","Sometimes", "Often","Always"))
                           # )
  cols<-names(cleaned)
  cleaned.factored<-lapply(cleaned[cols], as.factor)
  cleaned.search.data<-data.frame(cleaned[-c(1)])
  return(cleaned.search.data)
}
```

```{r}
search.data<-my.data.factored[c(3,4,7,8,10)]
search.data<-data.frame(search.data)
colnames(search.data)<-c( "Meal.Prepper","Dietary.Restriction","Primary","Enjoyed","NOT.Enjoyed")
cleaned.unfactored<-clean.mca(search.data)
dim(search.data)
mca.unfactored<-MCA(cleaned.unfactored,graph=FALSE)
fviz_screeplot(mca.unfactored,addlabels=T)
fviz_mca_var(mca.unfactored, choice = "mca.cor", repel = TRUE,
             ggtheme = theme_minimal())
fviz_contrib(mca.unfactored, choice = "var", axes = 1, top = 15)
fviz_mca_var(mca.unfactored, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, ggtheme = theme_minimal())
```

```{r}
search.data<-my.data.factored[c(6,7,12,13,14,15,24,25,26,27,29,30,31,34,35)]
search.data<-data.frame(search.data)
colnames(search.data)<-c( "Meal.Prepper","Dietary.Restriction","Primary","Enjoyed","NOT.Enjoyed")
cleaned.unfactored<-clean.mca(search.data)
mca.unfactored<-MCA(cleaned.unfactored,graph=FALSE)
fviz_screeplot(mca.unfactored,addlabels=T)
fviz_mca_var(mca.unfactored, choice = "mca.cor", repel = TRUE,
             ggtheme = theme_minimal())
fviz_contrib(mca.unfactored, choice = "var", axes = 1, top = 15)
fviz_mca_var(mca.unfactored, col.var = "cos2",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE, ggtheme = theme_minimal())
```
